{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9da58f-b50d-4e7f-9c6b-83cd7d9dd48e",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875403db-8850-4b76-8b6f-441c301c7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and define function for parsing\n",
    "from tika import parser\n",
    "def convertPdf2TxtWithTika(in_pdf_file, out_text_file):\n",
    "    # Load a file and extract information\n",
    "    print (\"INFO: - reading file = \" + in_pdf_file)\n",
    "    \n",
    "    raw = parser.from_file(in_pdf_file)\n",
    "    text = raw['content']\n",
    "    \n",
    "    ## Post-processing explained at: \n",
    "    # https://medium.com/@justinboylantoomey/fast-text-extraction-with-python-and-tika-41ac34b0fe61\n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    # Ensure text is utf-8 formatted\n",
    "    safe_text = text.encode('utf-8', errors='ignore')\n",
    "    # Escape any \\ issues\n",
    "    safe_text = str(safe_text).replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n",
    "    \n",
    "    # Write out extracted content\n",
    "    text_pdf = open(out_text_file, 'w')\n",
    "    print (\"INFO: - writing file = \" + out_text_file)\n",
    "    text_pdf.write(text)\n",
    "    text_pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c24cc-457c-40fc-83d0-3621b2a81d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pdf files in a directory and process its content\n",
    "import os\n",
    "import glob\n",
    "\n",
    "txtfiles = []\n",
    "inpath = 'resume/'\n",
    "outpath = 'out/'\n",
    "count = 0\n",
    "for file in glob.glob(inpath + '*.pdf'):\n",
    "    justfile = os.path.basename(file)\n",
    "    justfile = justfile.replace(\".pdf\",\"\")\n",
    "    print('INFO: processing file = ' + os.path.basename(file))\n",
    "    output_file = outpath + justfile + '.txt'\n",
    "    print('INFO: - in = ' + file + ', out = ' + output_file)\n",
    "    convertPdf2TxtWithTika(file, output_file)\n",
    "    count = count + 1\n",
    "print('INFO: processed total files = ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73915f9b-a191-4ee8-ac1d-7232d5f0b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define a function to do word cloud\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def wordcloud_draw(data, color = 'black'):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and not word.startswith('#')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000\n",
    "                     ).generate(cleaned_word)\n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef3b87-a319-4f94-9def-f397c09b6bc6",
   "metadata": {},
   "source": [
    "# Resume Exercise - Programming: Word Processing\n",
    "\n",
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047a985-f3e9-46a7-98e6-3052194e29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content in all files into one string \n",
    "file = 'out/JohnAydin-2024-Resume.txt'\n",
    "file_handle = open(file, 'r')\n",
    "content = str( file_handle.read()).split()\n",
    "#content_as_str = \" \".join(sorted(set(content), key=content.index))\n",
    "# Has duplicates\n",
    "my_content_as_str = \" \".join(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306e0b9-ee3e-451a-ba33-36b25be6c4cc",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b482-b1df-4626-8a99-35f23ef08529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "cnt = Counter(my_content_as_str.split())\n",
    "top100 = cnt.most_common(100)\n",
    "df = pd.DataFrame(top100, columns=['word', 'frequency'])\n",
    "df.plot(kind='bar', x='word', figsize=(18, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bf551-3f95-49ed-beb6-f206759cd74e",
   "metadata": {},
   "source": [
    "## 3-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed425d69-0d00-49e5-99d1-a4652793449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['|', 'and', 'a', 'in', 'to', 'the', 'with', '‚óè', 'of', 'for']\n",
    "for word in list(cnt):\n",
    "    if word in ignore:\n",
    "        del cnt[word]\n",
    "top100 = cnt.most_common(100)\n",
    "df = pd.DataFrame(top100, columns=['word', 'frequency'])\n",
    "df.plot(kind='bar', x='word', figsize=(18, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e48570-5806-4ac2-b0a2-ae7f7eae5e56",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "The frequencies are much lower and fairly evenly distributed with most only appering once. This is probalbly because I try fit as many key words as I can in my resume while not sounding repetative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f629b9-a854-4f0c-823e-f4ba2afdb32a",
   "metadata": {},
   "source": [
    "# Resume Exercise - Programming: Word Tag Cloud\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff342e2d-fdc0-4ad9-a755-39493b79d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do word tag cloud\n",
    "wordcloud_draw(my_content_as_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697e741-5dcd-4852-b06f-e82cc705be01",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b48014f-95c9-49ca-8074-5ad7ea426fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content in all files into one string \n",
    "pathFilesToUse = 'out/'\n",
    "\n",
    "all_content = ''\n",
    "count = 0\n",
    "for file in glob.glob(pathFilesToUse + '*.txt'):\n",
    "    print(\"file = \" + file)\n",
    "    file_handle = open(file, 'r')\n",
    "    content = str( file_handle.read()).split()\n",
    "    #content_as_str = \" \".join(sorted(set(content), key=content.index))\n",
    "    # Has duplicates\n",
    "    content_as_str = \" \".join(content)\n",
    "    # All together\n",
    "    all_content = all_content + content_as_str\n",
    "    #all_content.append(content)\n",
    "    count = count + 1\n",
    "    file_handle.close()\n",
    "\n",
    "print('INFO: processed total files = ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2ff7e-372c-4b25-9243-577940c3ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do word tag cloud\n",
    "wordcloud_draw(all_content.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663be5a-3aed-4174-b32b-432f8adcf07a",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "The coolest thing to me is seeing my name be the most frequent word in my word cloud since all of my socials include my name in their url.\n",
    "Another thing I noticed is that in my word cloud you can see the individual technologies that I put on my resume, but when looking at the whole class, everyone's unique experiences are drowned out by general words like technology or development. It's also interesting to see that enough people mentioned SQL and Git on their resume for it to show on the class's word cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
